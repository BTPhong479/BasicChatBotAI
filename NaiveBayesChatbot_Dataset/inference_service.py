import pickle
import os
import re
import nltk
from nltk.corpus import stopwords
from nlp.response_selector import ResponseSelector # Import Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i

# HÃ m tiá»n xá»­ lÃ½ (preprocess) giá»‘ng nhÆ° trong NaiveBayesClassifier
# Cáº§n pháº£i cÃ³ hÃ m nÃ y Ä‘á»ƒ tiá»n xá»­ lÃ½ input trÆ°á»›c khi dá»± Ä‘oÃ¡n
def preprocess_text(text, stop_words):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    tokens = text.split()
    filtered = [word for word in tokens if word not in stop_words]
    return ' '.join(filtered)

class ChatbotInference:
    def __init__(self, models_dir='models'):
        self.classifier_model = None
        self.vectorizer_model = None
        self.stop_words = None
        self.response_selector = None # ThÃªm biáº¿n Ä‘á»ƒ lÆ°u ResponseSelector

        try:
            self.stop_words = set(stopwords.words('english'))
        except LookupError:
            print("Stopwords not found, downloading...")
            nltk.download('stopwords')
            self.stop_words = set(stopwords.words('english'))

        # ÄÆ°á»ng dáº«n tá»›i cÃ¡c file model vÃ  data
        base_dir = '.' # Äáº£m báº£o base_dir lÃ  thÆ° má»¥c hiá»‡n táº¡i cá»§a chatbot
        classifier_filename = os.path.join(base_dir, models_dir, 'naive_bayes_classifier.pkl')
        vectorizer_filename = os.path.join(base_dir, models_dir, 'count_vectorizer.pkl')
        responses_path = os.path.join(base_dir, 'data', 'processed', 'intent_responses.json') # ÄÆ°á»ng dáº«n tá»›i file responses

        # Táº£i classifier (model Naive Bayes)
        with open(classifier_filename, 'rb') as f:
            self.classifier_model = pickle.load(f)
        print(f"âœ… ÄÃ£ táº£i classifier tá»«: {classifier_filename}")

        # Táº£i vectorizer (Ä‘á»ƒ chuyá»ƒn Ä‘á»•i vÄƒn báº£n sang dáº¡ng sá»‘)
        with open(vectorizer_filename, 'rb') as f:
            self.vectorizer_model = pickle.load(f)
        print(f"âœ… ÄÃ£ táº£i vectorizer tá»«: {vectorizer_filename}")

        # Táº£i bá»™ chá»n pháº£n há»“i
        self.response_selector = ResponseSelector(responses_path)
        print(f"âœ… ÄÃ£ táº£i bá»™ chá»n pháº£n há»“i tá»«: {responses_path}")

    # PhÆ°Æ¡ng thá»©c Ä‘á»ƒ dá»± Ä‘oÃ¡n intent (chá»‰ tráº£ vá» intent)
    def predict_intent(self, text):
        cleaned_text = preprocess_text(text, self.stop_words)
        X_vec = self.vectorizer_model.transform([cleaned_text])
        intent = self.classifier_model.predict(X_vec)[0]
        return intent

    # PhÆ°Æ¡ng thá»©c má»›i Ä‘á»ƒ láº¥y cáº£ intent vÃ  response
    def get_chatbot_response(self, user_input):
        intent = self.predict_intent(user_input) # Dá»± Ä‘oÃ¡n intent
        response = self.response_selector.get_response(intent) # Láº¥y pháº£n há»“i
        return intent, response # Tráº£ vá» cáº£ hai

# --- PHáº¦N KIá»‚M TRA TRá»°C TIáº¾P TRONG COLAB ---
if __name__ == "__main__":
    print("Äang khá»Ÿi táº¡o dá»‹ch vá»¥ dá»± Ä‘oÃ¡n chatbot...")
    inference_service = ChatbotInference()

    print("\nBáº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u há»i chatbot (nháº­p 'exit' hoáº·c 'quit' Ä‘á»ƒ thoÃ¡t):")
    while True:
        user_input = input("Báº¡n: ")
        if user_input.lower() in ['exit', 'quit']:
            break
        predicted_intent, chatbot_response = inference_service.get_chatbot_response(user_input)
        print(f"ğŸ‘‰ Intent dá»± Ä‘oÃ¡n: {predicted_intent}")
        print(f"ğŸ¤– Chatbot tráº£ lá»i: {chatbot_response}")